{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"mount_file_id":"1QkPDe0M9bFBRePekVg-ztj3sedtL01ZY","authorship_tag":"ABX9TyNPFs6ktIqEUE7LBHJYjOeu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c1de655b61a74e3b89eafb9d5e1b1e43":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_443acd3643b448e799b6ccd4baafee80","IPY_MODEL_efc2634b55404a67b5a978f002fec2cf","IPY_MODEL_033f8751253e452182d0188724cabfe8"],"layout":"IPY_MODEL_23afb401764a48ad90f8f6dfd8fc132d"}},"443acd3643b448e799b6ccd4baafee80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63b0fc75bf474c49b4570dead940cb9e","placeholder":"​","style":"IPY_MODEL_cd75f4540d04487ab2ef4526bd1d65d0","value":"Downloading: 100%"}},"efc2634b55404a67b5a978f002fec2cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96ac16a6aacf4f8a94ac1914aa40503b","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8041c8e68ef04d01a1370189fb618f54","value":570}},"033f8751253e452182d0188724cabfe8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7fe50b495e1419793de8a99a3276717","placeholder":"​","style":"IPY_MODEL_7ae56acd0581451c8dbfeadbbcb27e12","value":" 570/570 [00:00&lt;00:00, 17.1kB/s]"}},"23afb401764a48ad90f8f6dfd8fc132d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63b0fc75bf474c49b4570dead940cb9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd75f4540d04487ab2ef4526bd1d65d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96ac16a6aacf4f8a94ac1914aa40503b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8041c8e68ef04d01a1370189fb618f54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7fe50b495e1419793de8a99a3276717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ae56acd0581451c8dbfeadbbcb27e12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e0b541dbf04428289c4190e89ff1429":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8182cb45d2a843438e55971db82f537b","IPY_MODEL_f4746dfd95ec4ba49474161676604520","IPY_MODEL_f51eefa729bd4f0589ef867871fc3de9"],"layout":"IPY_MODEL_8a85189fa8ee4b3694f12efdf0a1579e"}},"8182cb45d2a843438e55971db82f537b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f108de3b0c5b41fc980516a2c9ab1475","placeholder":"​","style":"IPY_MODEL_50e8f45646f74785a0f7d90b2bf68a78","value":"Downloading: 100%"}},"f4746dfd95ec4ba49474161676604520":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41590ec661974a58820639074cb03985","max":536063208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2f5ca3842ba4c99b7ee5ed4a2d234b4","value":536063208}},"f51eefa729bd4f0589ef867871fc3de9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b68c0badf63d410896ccbabe3481a037","placeholder":"​","style":"IPY_MODEL_e6ef0d3d55524975a05a125134f00789","value":" 511M/511M [00:08&lt;00:00, 63.5MB/s]"}},"8a85189fa8ee4b3694f12efdf0a1579e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f108de3b0c5b41fc980516a2c9ab1475":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50e8f45646f74785a0f7d90b2bf68a78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41590ec661974a58820639074cb03985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2f5ca3842ba4c99b7ee5ed4a2d234b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b68c0badf63d410896ccbabe3481a037":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6ef0d3d55524975a05a125134f00789":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3eb37179b93480a9ac83faee5c0d682":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_742d7e0f50d440eeb5df7cf8309ca6fb","IPY_MODEL_f300a0caff764a4f8b957ff1a07dcc7f","IPY_MODEL_99340f400ec6489ea377163348fe9733"],"layout":"IPY_MODEL_eec7df22c17e4a4f8c33040de025a676"}},"742d7e0f50d440eeb5df7cf8309ca6fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac96c027cb7b4083a72f7c836cef08b7","placeholder":"​","style":"IPY_MODEL_e6066c32695449c5a678c2ea5af33eaa","value":"Downloading: 100%"}},"f300a0caff764a4f8b957ff1a07dcc7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_60a0457031244845b31251263d49ff88","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fa305d624254f7c8eb848f5cc5297e1","value":231508}},"99340f400ec6489ea377163348fe9733":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fba49839f2248c087c7f52a886d190a","placeholder":"​","style":"IPY_MODEL_9b2b6e2fd7d64ad4bb1136779011dea3","value":" 226k/226k [00:00&lt;00:00, 540kB/s]"}},"eec7df22c17e4a4f8c33040de025a676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac96c027cb7b4083a72f7c836cef08b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6066c32695449c5a678c2ea5af33eaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60a0457031244845b31251263d49ff88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fa305d624254f7c8eb848f5cc5297e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fba49839f2248c087c7f52a886d190a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b2b6e2fd7d64ad4bb1136779011dea3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6de27a15eb374ad3aac2c4930f59358b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_297fafb71c1549dab58730913024579f","IPY_MODEL_c077adaa2fe44a42a89176d98363c5e1","IPY_MODEL_a5f031a45cc14963bee4debe969cdc79"],"layout":"IPY_MODEL_1cd38acc363145df9886f00532402bce"}},"297fafb71c1549dab58730913024579f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83af4abdd92e4ca7b7249152055d3cc9","placeholder":"​","style":"IPY_MODEL_1291549a1b52410c8973e15b5c2c4d49","value":"Downloading: 100%"}},"c077adaa2fe44a42a89176d98363c5e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c4ba8801d5042228718873ebe809efb","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59316309bc834c6c877675f13dd5ca77","value":28}},"a5f031a45cc14963bee4debe969cdc79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cf67af83773424498647eb7c74ad622","placeholder":"​","style":"IPY_MODEL_7cc4495ed29d466a8e4a13a149781018","value":" 28.0/28.0 [00:00&lt;00:00, 988B/s]"}},"1cd38acc363145df9886f00532402bce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83af4abdd92e4ca7b7249152055d3cc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1291549a1b52410c8973e15b5c2c4d49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c4ba8801d5042228718873ebe809efb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59316309bc834c6c877675f13dd5ca77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0cf67af83773424498647eb7c74ad622":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cc4495ed29d466a8e4a13a149781018":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-LbYhzMfS5pC","executionInfo":{"status":"ok","timestamp":1652983535325,"user_tz":-180,"elapsed":18335,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"49b56e8c-61d4-4c58-86a8-fe6e1835b802"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 14.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 54.6 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 2.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 8.7 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"brKR1YsGSpHB","executionInfo":{"status":"ok","timestamp":1652983542833,"user_tz":-180,"elapsed":4472,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import transformers"]},{"cell_type":"code","source":["max_length = 128  # Maximum length of input sentence to the model.\n","batch_size = 32\n","epochs = 5\n","\n","# Labels in our dataset.\n","labels = [\"NOT ENTAILMENT - Unknown\", \"Entailment\", \"NOT ENTAILMENT - Contradiction\"]"],"metadata":{"id":"mPMp-xAHTAAR","executionInfo":{"status":"ok","timestamp":1652983545325,"user_tz":-180,"elapsed":519,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["PATH = '/content/drive/MyDrive/Colab Notebooks/ambiguous_knights_knaves.json'"],"metadata":{"id":"J9lX78wvTIUh","executionInfo":{"status":"ok","timestamp":1652983547164,"user_tz":-180,"elapsed":8,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import json\n","def read_jsonl_file(PATH):\n","  df = pd.read_json(PATH)\n","\n","  with open(PATH,'r') as f:\n","    data = json.loads(f.read())\n","\n","  df_nested_list = pd.json_normalize(data=data['puzzles'], record_path='QA', meta=['puzzle_text'])\n","  return df_nested_list"],"metadata":{"id":"ukkIuuOxTObP","executionInfo":{"status":"ok","timestamp":1652983549518,"user_tz":-180,"elapsed":847,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(read_jsonl_file(PATH))"],"metadata":{"id":"BMsfLMcWTd4B","executionInfo":{"status":"ok","timestamp":1652983551933,"user_tz":-180,"elapsed":439,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# SE IMPARTE DATASET-UL IN TRAIN, VALIDARE SI TEST\n","train_df = df[['qid','puzzle_text', 'question', 'answer']][:700]\n","valid_df  = df[['qid','puzzle_text', 'question', 'answer']]\n","test_df  = df[['qid','puzzle_text', 'question', 'answer']]\n","\n","# Shape of the data\n","print(f\"Total train samples : {train_df.shape[0]}\")\n","print(f\"Total validation samples: {valid_df.shape[0]}\")\n","print(f\"Total test samples: {test_df.shape[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhJqTUn7TVB9","executionInfo":{"status":"ok","timestamp":1652983553626,"user_tz":-180,"elapsed":13,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"e8bbfc39-d800-4152-8e6d-14c7cfcb2af8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Total train samples : 700\n","Total validation samples: 940\n","Total test samples: 940\n"]}]},{"cell_type":"code","source":["print(\"Train Target Distribution\")\n","print(train_df.answer.value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v92cgmPXTjMB","executionInfo":{"status":"ok","timestamp":1652983555866,"user_tz":-180,"elapsed":367,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"3ff5d1c0-16bc-4295-9ad2-864c0b49ac97"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Target Distribution\n","NOT ENTAILMENT - Unknown          536\n","Entailment                         82\n","NOT ENTAILMENT - Contradiction     82\n","Name: answer, dtype: int64\n"]}]},{"cell_type":"code","source":["print(\"Validation Target Distribution\")\n","print(valid_df.answer.value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AOoRdf1qTpAs","executionInfo":{"status":"ok","timestamp":1652983557442,"user_tz":-180,"elapsed":6,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"2f291611-0c56-48e9-e868-a1b8589082b8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Target Distribution\n","NOT ENTAILMENT - Unknown          730\n","Entailment                        105\n","NOT ENTAILMENT - Contradiction    105\n","Name: answer, dtype: int64\n"]}]},{"cell_type":"code","source":["train_df = (\n","    train_df[train_df.answer != \"-\"]\n","    .sample(frac=1.0, random_state=42)\n","    .reset_index(drop=True)\n",")\n","valid_df = (\n","    valid_df[valid_df.answer != \"-\"]\n","    .sample(frac=1.0, random_state=42)\n","    .reset_index(drop=True)\n",")"],"metadata":{"id":"ZbwfjGH2Ttvb","executionInfo":{"status":"ok","timestamp":1652983559062,"user_tz":-180,"elapsed":12,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_df[\"label\"] = train_df[\"answer\"].apply(\n","    lambda x: 0 if x == \"NOT ENTAILMENT - Contradiction\" else 1 if x == \"Entailment\" else 2\n",")\n","y_train = tf.keras.utils.to_categorical(train_df.label, num_classes=3)\n","\n","valid_df[\"label\"] = valid_df[\"answer\"].apply(\n","    lambda x: 0 if x == \"NOT ENTAILMENT - Contradiction\" else 1 if x == \"Entailment\" else 2\n",")\n","y_val = tf.keras.utils.to_categorical(valid_df.label, num_classes=3)\n","\n","test_df[\"label\"] = test_df[\"answer\"].apply(\n","    lambda x: 0 if x == \"NOT ENTAILMENT - Contradiction\" else 1 if x == \"Entailment\" else 2\n",")\n","y_test = tf.keras.utils.to_categorical(test_df.label, num_classes=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBxEdcI0TxL4","executionInfo":{"status":"ok","timestamp":1652983561226,"user_tz":-180,"elapsed":19,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"0927047d-d6d8-4bf1-e389-a1693140c29d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if sys.path[0] == '':\n"]}]},{"cell_type":"code","source":["class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n","    \"\"\"Generates batches of data.\n","\n","    Args:\n","        sentence_pairs: Array of premise and hypothesis input sentences.\n","        labels: Array of labels.\n","        batch_size: Integer batch size.\n","        shuffle: boolean, whether to shuffle the data.\n","        include_targets: boolean, whether to incude the labels.\n","\n","    Returns:\n","        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n","        (or just `[input_ids, attention_mask, `token_type_ids]`\n","         if `include_targets=False`)\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        sentence_pairs,\n","        labels,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        include_targets=True,\n","    ):\n","        self.sentence_pairs = sentence_pairs\n","        self.labels = labels\n","        self.shuffle = shuffle\n","        self.batch_size = batch_size\n","        self.include_targets = include_targets\n","        # Load our BERT Tokenizer to encode the text.\n","        # We will use base-base-uncased pretrained model.\n","        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n","            \"bert-base-uncased\", do_lower_case=True\n","        )\n","        self.indexes = np.arange(len(self.sentence_pairs))\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        # Denotes the number of batches per epoch.\n","        return len(self.sentence_pairs) // self.batch_size\n","\n","    def __getitem__(self, idx):\n","        # Retrieves the batch of index.\n","        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        sentence_pairs = self.sentence_pairs[indexes]\n","\n","        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n","        # encoded together and separated by [SEP] token.\n","        encoded = self.tokenizer.batch_encode_plus(\n","            sentence_pairs.tolist(),\n","            add_special_tokens=True,\n","            max_length=max_length,\n","            return_attention_mask=True,\n","            return_token_type_ids=True,\n","            pad_to_max_length=True,\n","            return_tensors=\"tf\",\n","        )\n","\n","        # Convert batch of encoded features to numpy array.\n","        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n","        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n","        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n","\n","        # Set to true if data generator is used for training/validation.\n","        if self.include_targets:\n","            labels = np.array(self.labels[indexes], dtype=\"int32\")\n","            return [input_ids, attention_masks, token_type_ids], labels\n","        else:\n","            return [input_ids, attention_masks, token_type_ids]\n","\n","    def on_epoch_end(self):\n","        # Shuffle indexes after each epoch if shuffle is set to True.\n","        if self.shuffle:\n","            np.random.RandomState(42).shuffle(self.indexes)"],"metadata":{"id":"V0ACX8zOT9Re","executionInfo":{"status":"ok","timestamp":1652983563838,"user_tz":-180,"elapsed":472,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Create the model under a distribution strategy scope.\n","strategy = tf.distribute.MirroredStrategy()\n","\n","with strategy.scope():\n","    # Encoded token ids from BERT tokenizer.\n","    input_ids = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n","    )\n","    # Attention masks indicates to the model which tokens should be attended to.\n","    attention_masks = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n","    )\n","    # Token type ids are binary masks identifying different sequences in the model.\n","    token_type_ids = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n","    )\n","    # Loading pretrained BERT model.\n","    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n","    # Freeze the BERT model to reuse the pretrained features without modifying them.\n","    bert_model.trainable = False \n","\n","    bert_output = bert_model(\n","        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n","    )\n","    sequence_output = bert_output.last_hidden_state\n","    pooled_output = bert_output.pooler_output\n","    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n","    bi_lstm = tf.keras.layers.Bidirectional(\n","        tf.keras.layers.LSTM(64, return_sequences=True)\n","    )(sequence_output)\n","    # Applying hybrid pooling approach to bi_lstm sequence output.\n","    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n","    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n","    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n","    dropout = tf.keras.layers.Dropout(0.3)(concat)\n","    avg_pool_2 = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n","    max_pool_2 = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n","    concat2 = tf.keras.layers.concatenate([avg_pool_2, max_pool_2])\n","    dropout2 = tf.keras.layers.Dropout(0.3)(concat2)\n","    dense1 = tf.keras.layers.Dense(1, activation='relu')(dropout2)     \n","    dense2 = tf.keras.layers.Dense(10, activation='sigmoid')(dense1) \n","    dense3 = tf.keras.layers.Dense(20, activation='sigmoid')(dense2) \n","    flatten = tf.keras.layers.Flatten()(dense3)\n","    output = tf.keras.layers.Dense(3, activation=\"softmax\")(flatten)\n","    model2 = tf.keras.models.Model(\n","        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n","    )\n","\n","    model2.compile(\n","        optimizer=tf.keras.optimizers.Adam(),\n","        loss=\"binary_crossentropy\",       # am schimbat loss function\n","        metrics=[\"acc\"],\n","    )\n","\n","\n","print(f\"Strategy: {strategy}\")\n","model2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c1de655b61a74e3b89eafb9d5e1b1e43","443acd3643b448e799b6ccd4baafee80","efc2634b55404a67b5a978f002fec2cf","033f8751253e452182d0188724cabfe8","23afb401764a48ad90f8f6dfd8fc132d","63b0fc75bf474c49b4570dead940cb9e","cd75f4540d04487ab2ef4526bd1d65d0","96ac16a6aacf4f8a94ac1914aa40503b","8041c8e68ef04d01a1370189fb618f54","e7fe50b495e1419793de8a99a3276717","7ae56acd0581451c8dbfeadbbcb27e12","7e0b541dbf04428289c4190e89ff1429","8182cb45d2a843438e55971db82f537b","f4746dfd95ec4ba49474161676604520","f51eefa729bd4f0589ef867871fc3de9","8a85189fa8ee4b3694f12efdf0a1579e","f108de3b0c5b41fc980516a2c9ab1475","50e8f45646f74785a0f7d90b2bf68a78","41590ec661974a58820639074cb03985","e2f5ca3842ba4c99b7ee5ed4a2d234b4","b68c0badf63d410896ccbabe3481a037","e6ef0d3d55524975a05a125134f00789"]},"id":"26pIhg5kUA6R","executionInfo":{"status":"ok","timestamp":1652983594742,"user_tz":-180,"elapsed":23974,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"09e900e4-0340-411d-d21b-0e3c687da3b9"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1de655b61a74e3b89eafb9d5e1b1e43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e0b541dbf04428289c4190e89ff1429"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","Strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f85948c8150>\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 128)]        0           []                               \n","                                                                                                  \n"," attention_masks (InputLayer)   [(None, 128)]        0           []                               \n","                                                                                                  \n"," token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n","                                tentions(last_hidde               'token_type_ids[0][0]']         \n","                                n_state=(None, 128,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 128, 128)     426496      ['tf_bert_model[0][0]']          \n","                                                                                                  \n"," global_average_pooling1d_1 (Gl  (None, 128)         0           ['bidirectional[0][0]']          \n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_max_pooling1d_1 (Global  (None, 128)         0           ['bidirectional[0][0]']          \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 256)          0           ['global_average_pooling1d_1[0][0\n","                                                                 ]',                              \n","                                                                  'global_max_pooling1d_1[0][0]'] \n","                                                                                                  \n"," dropout_38 (Dropout)           (None, 256)          0           ['concatenate_1[0][0]']          \n","                                                                                                  \n"," dense (Dense)                  (None, 1)            257         ['dropout_38[0][0]']             \n","                                                                                                  \n"," dense_1 (Dense)                (None, 10)           20          ['dense[0][0]']                  \n","                                                                                                  \n"," dense_2 (Dense)                (None, 20)           220         ['dense_1[0][0]']                \n","                                                                                                  \n"," flatten (Flatten)              (None, 20)           0           ['dense_2[0][0]']                \n","                                                                                                  \n"," dense_3 (Dense)                (None, 3)            63          ['flatten[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,909,296\n","Trainable params: 427,056\n","Non-trainable params: 109,482,240\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["train_data = BertSemanticDataGenerator(\n","    train_df[[\"puzzle_text\", \"question\"]].values.astype(\"str\"),\n","    y_train,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n","valid_data = BertSemanticDataGenerator(\n","    valid_df[[\"puzzle_text\", \"question\"]].values.astype(\"str\"),\n","    y_val,\n","    batch_size=batch_size,\n","    shuffle=False,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["f3eb37179b93480a9ac83faee5c0d682","742d7e0f50d440eeb5df7cf8309ca6fb","f300a0caff764a4f8b957ff1a07dcc7f","99340f400ec6489ea377163348fe9733","eec7df22c17e4a4f8c33040de025a676","ac96c027cb7b4083a72f7c836cef08b7","e6066c32695449c5a678c2ea5af33eaa","60a0457031244845b31251263d49ff88","2fa305d624254f7c8eb848f5cc5297e1","8fba49839f2248c087c7f52a886d190a","9b2b6e2fd7d64ad4bb1136779011dea3","6de27a15eb374ad3aac2c4930f59358b","297fafb71c1549dab58730913024579f","c077adaa2fe44a42a89176d98363c5e1","a5f031a45cc14963bee4debe969cdc79","1cd38acc363145df9886f00532402bce","83af4abdd92e4ca7b7249152055d3cc9","1291549a1b52410c8973e15b5c2c4d49","5c4ba8801d5042228718873ebe809efb","59316309bc834c6c877675f13dd5ca77","0cf67af83773424498647eb7c74ad622","7cc4495ed29d466a8e4a13a149781018"]},"id":"RST5PFgMUN71","executionInfo":{"status":"ok","timestamp":1652983606489,"user_tz":-180,"elapsed":5170,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"4c419a95-fd51-4478-8a1e-7e3e90876091"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3eb37179b93480a9ac83faee5c0d682"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6de27a15eb374ad3aac2c4930f59358b"}},"metadata":{}}]},{"cell_type":"code","source":["history = model2.fit(\n","    train_data,\n","    validation_data=valid_data,\n","    epochs=epochs,\n","    use_multiprocessing=True,\n","    workers=-1,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y1cy6L0wUPkg","executionInfo":{"status":"ok","timestamp":1652983715276,"user_tz":-180,"elapsed":104895,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"10b4d93f-4e08-4ac2-d6cd-9d6382f45ec6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","21/21 [==============================] - ETA: 0s - loss: 0.8008 - acc: 0.1190"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/21 [==============================] - 43s 949ms/step - loss: 0.8008 - acc: 0.1190 - val_loss: 0.7416 - val_acc: 0.1121\n","Epoch 2/5\n","21/21 [==============================] - 15s 717ms/step - loss: 0.6951 - acc: 0.1503 - val_loss: 0.6457 - val_acc: 0.7748\n","Epoch 3/5\n","21/21 [==============================] - 15s 729ms/step - loss: 0.6126 - acc: 0.7664 - val_loss: 0.5756 - val_acc: 0.7748\n","Epoch 4/5\n","21/21 [==============================] - 15s 740ms/step - loss: 0.5538 - acc: 0.7664 - val_loss: 0.5255 - val_acc: 0.7748\n","Epoch 5/5\n","21/21 [==============================] - 16s 760ms/step - loss: 0.5122 - acc: 0.7634 - val_loss: 0.4899 - val_acc: 0.7748\n"]}]},{"cell_type":"code","source":["# Unfreeze the bert_model.\n","bert_model.trainable = True\n","# Recompile the model to make the change effective.\n","model2.compile(\n","    optimizer=tf.keras.optimizers.Adam(1e-5),\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")\n","model2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sll2VI_U_bn","executionInfo":{"status":"ok","timestamp":1652983731700,"user_tz":-180,"elapsed":902,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"6b33ac95-e388-4a73-a901-15d7dab2b45c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 128)]        0           []                               \n","                                                                                                  \n"," attention_masks (InputLayer)   [(None, 128)]        0           []                               \n","                                                                                                  \n"," token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n","                                tentions(last_hidde               'token_type_ids[0][0]']         \n","                                n_state=(None, 128,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 128, 128)     426496      ['tf_bert_model[0][0]']          \n","                                                                                                  \n"," global_average_pooling1d_1 (Gl  (None, 128)         0           ['bidirectional[0][0]']          \n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_max_pooling1d_1 (Global  (None, 128)         0           ['bidirectional[0][0]']          \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 256)          0           ['global_average_pooling1d_1[0][0\n","                                                                 ]',                              \n","                                                                  'global_max_pooling1d_1[0][0]'] \n","                                                                                                  \n"," dropout_38 (Dropout)           (None, 256)          0           ['concatenate_1[0][0]']          \n","                                                                                                  \n"," dense (Dense)                  (None, 1)            257         ['dropout_38[0][0]']             \n","                                                                                                  \n"," dense_1 (Dense)                (None, 10)           20          ['dense[0][0]']                  \n","                                                                                                  \n"," dense_2 (Dense)                (None, 20)           220         ['dense_1[0][0]']                \n","                                                                                                  \n"," flatten (Flatten)              (None, 20)           0           ['dense_2[0][0]']                \n","                                                                                                  \n"," dense_3 (Dense)                (None, 3)            63          ['flatten[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,909,296\n","Trainable params: 109,909,296\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["history = model2.fit(\n","    train_data,\n","    validation_data=valid_data,\n","    epochs=epochs,\n","    use_multiprocessing=True,\n","    workers=-1,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-oaFmqlKVDek","executionInfo":{"status":"ok","timestamp":1652983884694,"user_tz":-180,"elapsed":148937,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"4f357b7c-62ff-4cd2-f13e-73c1a0a82985"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","21/21 [==============================] - 48s 1s/step - loss: 0.4957 - accuracy: 0.7634 - val_loss: 0.4895 - val_accuracy: 0.7748\n","Epoch 2/5\n","21/21 [==============================] - 25s 1s/step - loss: 0.4934 - accuracy: 0.7664 - val_loss: 0.4890 - val_accuracy: 0.7748\n","Epoch 3/5\n","21/21 [==============================] - 25s 1s/step - loss: 0.4923 - accuracy: 0.7679 - val_loss: 0.4886 - val_accuracy: 0.7748\n","Epoch 4/5\n","21/21 [==============================] - 25s 1s/step - loss: 0.4950 - accuracy: 0.7619 - val_loss: 0.4881 - val_accuracy: 0.7748\n","Epoch 5/5\n","21/21 [==============================] - 25s 1s/step - loss: 0.4907 - accuracy: 0.7679 - val_loss: 0.4877 - val_accuracy: 0.7748\n"]}]},{"cell_type":"code","source":["test_data = BertSemanticDataGenerator(\n","    test_df[[\"puzzle_text\", \"question\"]].values.astype(\"str\"),\n","    y_test,\n","    batch_size=batch_size,\n","    shuffle=False,\n",")\n","model2.evaluate(test_data, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3_TMBuiVGKp","executionInfo":{"status":"ok","timestamp":1652983898758,"user_tz":-180,"elapsed":11313,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"3c4c13b7-a9c2-4b48-c77c-418beb5c5fca"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 9s 290ms/step - loss: 0.4881 - accuracy: 0.7737\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.4881480038166046, 0.7737069129943848]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["def check_similarity(sentence1, sentence2):\n","    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n","    test_data = BertSemanticDataGenerator(\n","        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n","    )\n","\n","    proba = model2.predict(test_data[0])[0]\n","    idx = np.argmax(proba)\n","    proba = f\"{proba[idx]: .2f}%\"\n","    pred = labels[idx]\n","    return pred, proba"],"metadata":{"id":"TYeHfLeKXlw4","executionInfo":{"status":"ok","timestamp":1652983911904,"user_tz":-180,"elapsed":413,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["sentence1 = \"On the island where each inhabitant is either a knave or a knight , knights always tell the truth while knaves always lie . You meet three inhabitants : Alice , Rex and Bob .  Rex claims that it is false that Bob is a knave . Bob says that he is a knight or Alice is a knight . Can you determine who is a knight and who is a knave ?\"\n","sentence2 = \"Is Rex the knight ?\"\n","check_similarity(sentence1, sentence2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wj-rc8XXqjA","executionInfo":{"status":"ok","timestamp":1652983920733,"user_tz":-180,"elapsed":6183,"user":{"displayName":"Izabella Bartalus","userId":"14250698818363907854"}},"outputId":"f9f03d55-dddc-4db7-8d23-b4c0ef02530f"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["('NOT ENTAILMENT - Contradiction', ' 0.70%')"]},"metadata":{},"execution_count":23}]}]}